{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berserk21/Berserk21/blob/main/VIDYA_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai\n",
        "!pip install pyttsx3"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F_-x7deqGZqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install espeak"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q8ylT7nLHxyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pyttsx3  # For text-to-speech conversion\n",
        "\n",
        "# Ask the user what they want to learn\n",
        "user_defined_topic = input(\"What topic would you like to learn about? \")\n",
        "\n",
        "# Questions to personalize the teaching transcript\n",
        "questions = [\n",
        "    {\n",
        "        \"question\": \"What is your preferred way of engaging with learning materials?\",\n",
        "        \"options\": [\n",
        "            \"Listening to explanations or discussions (auditory).\",\n",
        "            \"Experimenting and applying concepts (hands-on).\",\n",
        "            \"Reading and analyzing written content (visual/reading).\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"When learning a new topic, what do you find most challenging?\",\n",
        "        \"options\": [\n",
        "            \"Understanding abstract concepts without examples.\",\n",
        "            \"Staying focused when there are no interactive elements.\",\n",
        "            \"Organizing large amounts of information effectively.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do you prefer to receive feedback on your learning?\",\n",
        "        \"options\": [\n",
        "            \"Immediate feedback during the process.\",\n",
        "            \"Detailed feedback after completing tasks.\",\n",
        "            \"Opportunities for self-reflection and self-assessment.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What motivates you most in learning a new subject?\",\n",
        "        \"options\": [\n",
        "            \"Exploring new ideas and satisfying curiosity.\",\n",
        "            \"Achieving specific goals or solving real-world problems.\",\n",
        "            \"Acquiring skills that are directly relevant to your career.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do you approach complex problems?\",\n",
        "        \"options\": [\n",
        "            \"Breaking them down into smaller, manageable steps.\",\n",
        "            \"Brainstorming creative solutions and thinking outside the box.\",\n",
        "            \"Analyzing similar problems and applying tried-and-tested methods.\"\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "answers = []\n",
        "\n",
        "def ask_question(question_data):\n",
        "    print(question_data[\"question\"])\n",
        "    for i, option in enumerate(question_data[\"options\"], 1):\n",
        "        print(f\"{i}. {option}\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            choice = int(input(\"Enter the number corresponding to your choice: \"))\n",
        "            if 1 <= choice <= len(question_data[\"options\"]):\n",
        "                answers.append(question_data[\"options\"][choice - 1])\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please choose a valid option.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a valid number.\")\n",
        "\n",
        "# Ask all questions and collect answers\n",
        "for question in questions:\n",
        "    ask_question(question)\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyDbxPtp6KI9AdKzrMZr1Jja9bria-luOXs\")\n",
        "\n",
        "# Construct a personalized prompt for teaching\n",
        "prompt = f\"\"\"\n",
        "Based on the user's learning preferences, challenges, and problem-solving style, generate a highly personalized teaching.\n",
        "Here are the details to consider:\n",
        "\n",
        "1. **Learning Topic**: {user_defined_topic}\n",
        "   - Focus on making this topic engaging and accessible based on the user's preferences.\n",
        "\n",
        "2. **Preferred Learning Style**: {answers[0]}\n",
        "   - Include interactive and practical examples where the user can actively participate.\n",
        "\n",
        "3. **Information Processing Challenge**: {answers[1]}\n",
        "   - Address this challenge by providing clear examples, engaging interactions, or structured explanations.\n",
        "\n",
        "4. **Feedback Preference**: {answers[2]}\n",
        "   - Provide feedback in the preferred manner, such as during or after learning tasks.\n",
        "\n",
        "5. **Motivation to Learn**: {answers[3]}\n",
        "   - Focus on engaging content that sparks curiosity and highlights the intrinsic value of the subject.\n",
        "\n",
        "6. **Problem-Solving Style**: {answers[4]}\n",
        "   - Present problems and solutions systematically, emphasizing logic and clear steps.\n",
        "\n",
        "The speech should:\n",
        "- Begin with an engaging introduction tailored to these preferences.\n",
        "- Use real-world applications and hands-on exercises to teach the material.\n",
        "- Include check-in points or mini-quizzes to ensure comprehension.\n",
        "- Maintain a conversational tone to keep the user motivated.\n",
        "\n",
        "Create 1 minute speech for teaching the topic: {user_defined_topic}.\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the Gemini model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Generate the personalized teaching transcript\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Print the generated text\n",
        "print(\"\\nPersonalized Teaching Transcript:\")\n",
        "teaching_text = response.text\n",
        "print(teaching_text)"
      ],
      "metadata": {
        "id": "4U2jO9ipL4ao",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "11!pip install gtts"
      ],
      "metadata": {
        "id": "rtwdJiW2MAxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "# Assuming `teaching_text` contains the generated teaching transcript\n",
        "audio_file = \"teaching_transcript.mp3\"\n",
        "\n",
        "# Generate audio using Google Text-to-Speech\n",
        "tts = gTTS(teaching_text, lang='en', slow=False)  # Set `slow=True` for clearer speech\n",
        "tts.save(audio_file)\n",
        "\n",
        "print(f\"\\nThe teaching transcript has been saved as an audio file: {audio_file}\")\n"
      ],
      "metadata": {
        "id": "61yDvjCTL6bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/FurkanGozukara/roop\n",
        "%cd roop\n",
        "#Tested and updated 23 August 2023 commit\n",
        "#!git checkout da1ef285f1d43bd0cc8b9cdb9a0f80f7ae793a97\n",
        "!pip install onnxruntime-gpu==1.18.0 && pip install -r requirements.txt\n",
        "!pip install onnxruntime-gpu==1.18.0 --upgrade\n",
        "!apt-get update --yes\n",
        "!apt install nvidia-cuda-toolkit --yes\n",
        "!pip install opennsfw2 keras --upgrade\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "dtxTzWSRaENT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/roop\"\n",
        "!python run.py -s \"path_of_picture\" -t \"path_of_video\" -o \"face_restored_video3.mp4\" --keep-frames --keep-fps --temp-frame-quality 1 --output-video-quality 1 --execution-provider cuda --frame-processor face_swapper face_enhancer"
      ],
      "metadata": {
        "id": "gXDwBhJM3aAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, clear_output\n",
        "!rm -rf /content/sample_data\n",
        "!mkdir /content/sample_data\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/justinjohn0306/Wav2Lip\n",
        "\n",
        "%cd /content/Wav2Lip\n",
        "\n",
        "#download the pretrained model\n",
        "!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip.pth' -O 'checkpoints/wav2lip.pth'\n",
        "!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip_gan.pth' -O 'checkpoints/wav2lip_gan.pth'\n",
        "!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/resnet50.pth' -O 'checkpoints/resnet50.pth'\n",
        "!wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/mobilenet.pth' -O 'checkpoints/mobilenet.pth'\n",
        "a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
        "!pip install git+https://github.com/elliottzheng/batch-face.git@master\n",
        "!pip install ffmpeg-python mediapipe==0.10.18\n",
        "\n",
        "print(\"All set and ready!\")\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from IPython.display import HTML, clear_output\n",
        "from base64 import b64encode\n",
        "import moviepy.editor as mp\n",
        "\n",
        "\n",
        "def showVideo(file_path):\n",
        "    \"\"\"Function to display video in Colab\"\"\"\n",
        "    mp4 = open(file_path, 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(f\"\"\"\n",
        "    <video controls width=600>\n",
        "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\"))\n",
        "\n",
        "\n",
        "def get_video_resolution(video_path):\n",
        "    \"\"\"Function to get the resolution of a video\"\"\"\n",
        "    import cv2\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    return (width, height)\n",
        "\n",
        "\n",
        "# Remove previous input video if it exists\n",
        "if os.path.isfile('/content/sample_data/input_vid.mp4'):\n",
        "    os.remove('/content/sample_data/input_vid.mp4')\n",
        "\n",
        "# Custom Path for video\n",
        "PATH_TO_YOUR_VIDEO = '/content/roop/face_restored_video3.mp4'  # Specify your video path here\n",
        "if not os.path.isfile(PATH_TO_YOUR_VIDEO):\n",
        "    print(\"ERROR: File not found!\")\n",
        "    raise SystemExit(0)\n",
        "\n",
        "# Check video duration\n",
        "video_duration = mp.VideoFileClip(PATH_TO_YOUR_VIDEO).duration\n",
        "if video_duration > 60:\n",
        "    print(\"WARNING: Video duration exceeds 60 seconds. Please use a shorter video.\")\n",
        "    raise SystemExit(0)\n",
        "\n",
        "# Check video resolution and resize if necessary\n",
        "video_resolution = get_video_resolution(PATH_TO_YOUR_VIDEO)\n",
        "print(f\"Video resolution: {video_resolution}\")\n",
        "if video_resolution[0] >= 1920 or video_resolution[1] >= 1080:\n",
        "    print(\"Resizing video to 720p...\")\n",
        "    os.system(f\"ffmpeg -i '{PATH_TO_YOUR_VIDEO}' -vf scale=1280:720 /content/sample_data/input_vid.mp4\")\n",
        "    PATH_TO_YOUR_VIDEO = \"/content/sample_data/input_vid.mp4\"\n",
        "    print(\"Video resized to 720p\")\n",
        "else:\n",
        "    print(\"No resizing needed\")\n",
        "    shutil.copyfile(PATH_TO_YOUR_VIDEO, \"/content/sample_data/input_vid.mp4\")\n",
        "\n",
        "\n",
        "import os\n",
        "from IPython.display import Audio, clear_output\n",
        "from google.colab import drive\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Remove previous input audio if it exists\n",
        "if os.path.isfile('/content/sample_data/input_audio.wav'):\n",
        "    os.remove('/content/sample_data/input_audio.wav')\n",
        "\n",
        "# Specify the path to your audio file\n",
        "PATH_TO_YOUR_AUDIO = 'path_of_audio'  # Add your custom audio path here\n",
        "if not os.path.isfile(PATH_TO_YOUR_AUDIO):\n",
        "    print(\"ERROR: File not found!\")\n",
        "    raise SystemExit(0)\n",
        "\n",
        "# Load the audio file with its original sampling rate\n",
        "audio, sr = librosa.load(PATH_TO_YOUR_AUDIO, sr=None)\n",
        "\n",
        "# Save the audio as WAV in the specified directory\n",
        "sf.write('/content/sample_data/input_audio.wav', audio, sr, format='wav')\n",
        "\n",
        "# Display the audio player\n",
        "clear_output()\n",
        "\n",
        "\n",
        "\n",
        "%cd /content/Wav2Lip\n",
        "\n",
        "# Set up paths and variables for the output file\n",
        "output_file_path = '/content/Wav2Lip/results/result_voice.mp4'\n",
        "\n",
        "# Delete existing output file before processing, if any\n",
        "if os.path.exists(output_file_path):\n",
        "    os.remove(output_file_path)\n",
        "\n",
        "pad_top =  0\n",
        "pad_bottom =  10\n",
        "pad_left =  0\n",
        "pad_right =  0\n",
        "rescaleFactor =  1\n",
        "nosmooth = True\n",
        "use_hd_model = True\n",
        "checkpoint_path = 'checkpoints/wav2lip.pth' if not use_hd_model else 'checkpoints/wav2lip_gan.pth'\n",
        "\n",
        "\n",
        "if nosmooth == False:\n",
        "  !python inference.py --checkpoint_path $checkpoint_path --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor\n",
        "else:\n",
        "  !python inference.py --checkpoint_path $checkpoint_path --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor --nosmooth\n",
        "\n",
        "#Preview output video\n",
        "if os.path.exists(output_file_path):\n",
        "    clear_output()\n",
        "    print(\"Final Video Preview\")\n",
        "    print(\"Download this video from\", output_file_path)\n",
        "    showVideo(output_file_path)\n",
        "else:\n",
        "    print(\"Processing failed. Output video not found.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VSdRUxdU3Z9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}